{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import regex as re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "# Load the pandas DataFrame with your data\n",
    "df = pd.read_csv('chemical.csv') ## Dataframe contains Name column which contains chemical names\n",
    "df = df.head(50)\n",
    "def process_chemical(chemical_name):\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    # Load the PubChem page\n",
    "    url = f'https://pubchem.ncbi.nlm.nih.gov/compound/{chemical_name.replace(\" \", \"%20\")}'\n",
    "    driver.get(url)\n",
    "    driver.minimize_window()\n",
    "    \n",
    "    # Check if the page exists\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//h1[contains(text(), \"Page Not Found\")]')\n",
    "        print(f\"Compound {chemical_name} not found\")\n",
    "        driver.quit()\n",
    "        return\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    button = driver.find_element(By.XPATH, '//*[@id=\"page-download-btn\"]')\n",
    "    button.click()\n",
    "    button1 = driver.find_element(By.XPATH,'//*[@id=\"root-modal\"]/div[2]/div/div[2]/div/div/div[2]/div/div[1]/ul/li[2]/div/a[2]')\n",
    "    button1.click()\n",
    "    \n",
    "    # Wait for the new page to load and get the URL\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    url = driver.current_url\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Extract data between <String> tags using regex\n",
    "    pattern = r\"<String>([A-Za-z0-9\\-.,() ]*)\\.</String>\"\n",
    "    file_contents = response.content.decode(\"utf-8\")\n",
    "    matches = re.findall(pattern, file_contents, re.DOTALL)\n",
    "    \n",
    "    # Filter lines that contain \"LLC\" or \"LTD\"\n",
    "    filtered_lines = [line for line in matches if not re.search(r\"\\bLLC\\b|\\bInc\\b\", line)]\n",
    "    \n",
    "    # Write the filtered data to a new text file\n",
    "    output_file = f\"{chemical_name}_filtered_data.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for line in filtered_lines:\n",
    "            file.write(line + \".\\n\")\n",
    "    print(\"Filtered data saved to\", output_file)\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "# Get the absolute path of the current working directory\n",
    "current_dir = os.path.abspath('.')\n",
    "# Iterate over each row of the DataFrame and create folders for each name\n",
    "for _, row in df.iterrows():\n",
    "    folder_name = str(row['name'])\n",
    "    folder_path = os.path.join(current_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Iterate over each synonym and scrape the description\n",
    "    synonym_list = row['synonym']\n",
    "    synonym_list = str(synonym_list).strip().split('; ')\n",
    "    \n",
    "    for synonym in synonym_list:\n",
    "        process_chemical(synonym)\n",
    "    \n",
    "    # Move the filtered data file to the folder\n",
    "        filtered_data_file_name = f\"{synonym}_filtered_data.txt\"\n",
    "        filtered_data_file_path = os.path.join(current_dir, filtered_data_file_name)\n",
    "    \n",
    "        if os.path.exists(filtered_data_file_path):\n",
    "            new_filtered_data_file_path = os.path.join(folder_path, filtered_data_file_name)\n",
    "            os.rename(filtered_data_file_path, new_filtered_data_file_path)\n",
    "        \n",
    "        # Extract the first 6 lines from the filtered data file\n",
    "            description_file_name = f\"{synonym}_description.txt\"\n",
    "        # Remove special characters from the file name\n",
    "            description_file_name = ''.join(c for c in description_file_name if c.isalnum() or c.isspace()).rstrip()\n",
    "            description_file_path = os.path.join(folder_path, description_file_name)\n",
    "        \n",
    "            with open(new_filtered_data_file_path, 'r', encoding=\"utf-8\") as file:\n",
    "               filtered_data = file.readlines()[:6]\n",
    "        \n",
    "        # Write the first 6 lines to a separate text file\n",
    "            with open(description_file_path, 'w') as file:\n",
    "               file.writelines(filtered_data)\n",
    "        \n",
    "        # Delete the filtered data file\n",
    "            os.remove(new_filtered_data_file_path)\n",
    "    \n",
    "        else:\n",
    "            print(f\"Filtered data file {filtered_data_file_name} not found for {synonym}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
